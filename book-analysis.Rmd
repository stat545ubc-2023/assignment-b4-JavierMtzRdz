---
title: "Book Analysis"
author: Javier Mtz.-Rdz.
output: github_document
---

# Setup

For this assignment, we will need to load the following packages.

```{r message=FALSE, warning=FALSE}
library(janeaustenr)
library(tidytext)
library(tidyverse)
library(mytidyfunctions)
```

# Exercise 1-2: Make and Document your Function

In this section, I developed a function to create an index within a tidy dataset.

```{r}
# Get the text of The divine comedy by Dante Alighieri
book <- read.table("https://dev.gutenberg.org/cache/epub/8800/pg8800.txt",
                   sep =  "\t",
                   skip = 156,
                   nrows = 14015) %>% 
  rename(txt = 1) 

book_clean <- book %>% 
  mutate(all_upp = ifelse(str_to_upper(txt) == txt, txt, NA),
         part = ifelse(str_detect(all_upp, "CANTO"), NA, all_upp),
         part = recode(part, "OR THE INFERNO" = "HELL"),
         canto = ifelse(str_detect(all_upp, "CANTO"), all_upp, NA)) %>% 
  fill(part, canto) %>% 
  filter(is.na(all_upp)) %>% 
  select(-all_upp)


# Tokenize the text
words <- book_clean %>% 
  unnest_tokens(word, txt)

# Load stopwords from the tidytext package
mit_sw <- read.table("https://www.mit.edu/~ecprice/wordlist.10000",
                   sep =  "\t") %>% 
  rename(word = 1)
tdy_txt_sw <- tibble(tidytext::stop_words)

# stop_words <- unique(c(tdy_txt_sw$word,
#                 mit_sw$V1))


# Remove stopwords
filtered_words <- anti_join(words, mit_sw)

# Get the most common words
top_words <- filtered_words %>%
  group_by(part) %>% 
  count(word, sort = TRUE) %>%
  top_n(10)

# Plot the most common words
ggplot(top_words, aes(x = fct_reorder(word, n), y = n)) +
  facet_wrap(~str_to_sentence(part),
             ncol = 1,
             scales = "free_x") +
  geom_col() +
  geom_text_bi(aes(label = n),
               fontface = "bold") +
  labs(title = "Most Common Words in The Divine Comedy by Part",
       x = "Word",
       y = "Frequency") +
  mi_tema(axis.text.x = element_text(angle = 45, hjust = 1))
```

